{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMAj2Wcvb1VZ5jfVglDCUfg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeoyyeoyyyu/yeon/blob/main/model/VGG/VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "원본 논문 링크\n",
        "- https://arxiv.org/pdf/1409.1556.pdf%20http://arxiv.org/abs/1409.1556.pdf"
      ],
      "metadata": {
        "id": "ZY2dx_26GN4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D, Dense, Dropout\n",
        "from keras.layers import BatchNormalization, Activation\n",
        "from keras.models import Model"
      ],
      "metadata": {
        "id": "wvEYjVQKHRz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = Input([224, 224, 3], dtype=tf.float32)\n",
        "\n",
        "x = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(input)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Conv2D(64, (3, 3), padding=\"same\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
        "\n",
        "x = Conv2D(128, (3, 3), padding=\"same\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Conv2D(128, (3, 3), padding=\"same\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
        "\n",
        "x = Conv2D(256, (3, 3), padding=\"same\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Conv2D(256, (3, 3), padding=\"same\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Conv2D(256, (3, 3), padding=\"same\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "# add for VGG19\n",
        "# x = Conv2D(256, (3, 3), padding=\"same\")(x)\n",
        "# x = BatchNormalization()(x)\n",
        "# x = Activation(\"relu\")(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
        "\n",
        "x = Conv2D(512, (3, 3), padding=\"same\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Conv2D(512, (3, 3), padding=\"same\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Conv2D(512, (3, 3), padding=\"same\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "# add for VGG19\n",
        "# x = Conv2D(512, (3, 3), padding=\"same\")(x)\n",
        "# x = BatchNormalization()(x)\n",
        "# x = Activation(\"relu\")(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
        "\n",
        "x = Conv2D(512, (3, 3), padding=\"same\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Conv2D(512, (3, 3), padding=\"same\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Conv2D(512, (3, 3), padding=\"same\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "# add for VGG19\n",
        "# x = Conv2D(512, (3, 3), padding=\"same\")(x)\n",
        "# x = BatchNormalization()(x)\n",
        "# x = Activation(\"relu\")(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "# x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "x = Dense(4096)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = Dense(4096)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "output = Dense(1000, activation=\"softmax\")(x)\n",
        "\n",
        "model = Model(inputs=input, outputs=output)"
      ],
      "metadata": {
        "id": "pajG9dY4HdHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RncD56cMV_z",
        "outputId": "6be43fb2-c7fa-45f1-ff51-496e5aace314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_11 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " conv2d_143 (Conv2D)         (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " batch_normalization_162 (Ba  (None, 224, 224, 64)     256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_162 (Activation)  (None, 224, 224, 64)     0         \n",
            "                                                                 \n",
            " conv2d_144 (Conv2D)         (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " batch_normalization_163 (Ba  (None, 224, 224, 64)     256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_163 (Activation)  (None, 224, 224, 64)     0         \n",
            "                                                                 \n",
            " max_pooling2d_50 (MaxPoolin  (None, 112, 112, 64)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_145 (Conv2D)         (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " batch_normalization_164 (Ba  (None, 112, 112, 128)    512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_164 (Activation)  (None, 112, 112, 128)    0         \n",
            "                                                                 \n",
            " conv2d_146 (Conv2D)         (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " batch_normalization_165 (Ba  (None, 112, 112, 128)    512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_165 (Activation)  (None, 112, 112, 128)    0         \n",
            "                                                                 \n",
            " max_pooling2d_51 (MaxPoolin  (None, 56, 56, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_147 (Conv2D)         (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_166 (Ba  (None, 56, 56, 256)      1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_166 (Activation)  (None, 56, 56, 256)      0         \n",
            "                                                                 \n",
            " conv2d_148 (Conv2D)         (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_167 (Ba  (None, 56, 56, 256)      1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_167 (Activation)  (None, 56, 56, 256)      0         \n",
            "                                                                 \n",
            " conv2d_149 (Conv2D)         (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_168 (Ba  (None, 56, 56, 256)      1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_168 (Activation)  (None, 56, 56, 256)      0         \n",
            "                                                                 \n",
            " max_pooling2d_52 (MaxPoolin  (None, 28, 28, 256)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_150 (Conv2D)         (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " batch_normalization_169 (Ba  (None, 28, 28, 512)      2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_169 (Activation)  (None, 28, 28, 512)      0         \n",
            "                                                                 \n",
            " conv2d_151 (Conv2D)         (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " batch_normalization_170 (Ba  (None, 28, 28, 512)      2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_170 (Activation)  (None, 28, 28, 512)      0         \n",
            "                                                                 \n",
            " conv2d_152 (Conv2D)         (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " batch_normalization_171 (Ba  (None, 28, 28, 512)      2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_171 (Activation)  (None, 28, 28, 512)      0         \n",
            "                                                                 \n",
            " max_pooling2d_53 (MaxPoolin  (None, 14, 14, 512)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_153 (Conv2D)         (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " batch_normalization_172 (Ba  (None, 14, 14, 512)      2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_172 (Activation)  (None, 14, 14, 512)      0         \n",
            "                                                                 \n",
            " conv2d_154 (Conv2D)         (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " batch_normalization_173 (Ba  (None, 14, 14, 512)      2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_173 (Activation)  (None, 14, 14, 512)      0         \n",
            "                                                                 \n",
            " conv2d_155 (Conv2D)         (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " batch_normalization_174 (Ba  (None, 14, 14, 512)      2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_174 (Activation)  (None, 14, 14, 512)      0         \n",
            "                                                                 \n",
            " max_pooling2d_54 (MaxPoolin  (None, 7, 7, 512)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 4096)              102764544 \n",
            "                                                                 \n",
            " batch_normalization_175 (Ba  (None, 4096)             16384     \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_175 (Activation)  (None, 4096)             0         \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 4096)              16781312  \n",
            "                                                                 \n",
            " batch_normalization_176 (Ba  (None, 4096)             16384     \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_176 (Activation)  (None, 4096)             0         \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 138,407,208\n",
            "Trainable params: 138,382,376\n",
            "Non-trainable params: 24,832\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def VGG_Conv2D(input, loop=2, f=64, k=(3, 3), s=(1, 1), p=\"same\"):\n",
        "    \"\"\"\n",
        "    input: input tensor of Convolution layer\n",
        "    loop: Number of iterations of Conv-Pooling\n",
        "    f: filter size of Conv\n",
        "    k: kernel size of Conv\n",
        "    s: stride size of Conv\n",
        "    p: padding status of Conv\n",
        "    \"\"\"\n",
        "    z = Conv2D(filters=f, kernel_size=k, strides=s, padding=p)(input)\n",
        "    z = BatchNormalization()(z)\n",
        "    z = Activation(\"relu\")(z)\n",
        "\n",
        "    for i in range(loop - 1):\n",
        "        z = Conv2D(filters=f, kernel_size=k, strides=s, padding=p)(z)\n",
        "        z = BatchNormalization()(z)\n",
        "        z = Activation(\"relu\")(z)\n",
        "    z = MaxPooling2D(pool_size=(2, 2), strides=2)(z)\n",
        "    return z"
      ],
      "metadata": {
        "id": "oYH7F5JqNBD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = Input([224, 224, 3], dtype=tf.float32)\n",
        "\n",
        "x = VGG_Conv2D(input, loop=2, f=64, k=(3, 3), s=(1, 1), p=\"same\")\n",
        "x = VGG_Conv2D(x, f=128)\n",
        "x = VGG_Conv2D(x, loop=3, f=256)\n",
        "x = VGG_Conv2D(x, loop=3, f=512)\n",
        "x = VGG_Conv2D(x, loop=3, f=512)\n",
        "\n",
        "x = Flatten()(x)\n",
        "# x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "x = Dense(4096)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = Dense(4096)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "output = Dense(1000, activation=\"softmax\")(x)\n",
        "\n",
        "model = Model(inputs=input, outputs=output)"
      ],
      "metadata": {
        "id": "_9zLd8C-VYma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joNhP-jeWjEW",
        "outputId": "84fca875-460c-4ca7-ba70-4de2f738ab75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_14 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " conv2d_182 (Conv2D)         (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " batch_normalization_207 (Ba  (None, 224, 224, 64)     256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_207 (Activation)  (None, 224, 224, 64)     0         \n",
            "                                                                 \n",
            " conv2d_183 (Conv2D)         (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " batch_normalization_208 (Ba  (None, 224, 224, 64)     256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_208 (Activation)  (None, 224, 224, 64)     0         \n",
            "                                                                 \n",
            " max_pooling2d_65 (MaxPoolin  (None, 112, 112, 64)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_184 (Conv2D)         (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " batch_normalization_209 (Ba  (None, 112, 112, 128)    512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_209 (Activation)  (None, 112, 112, 128)    0         \n",
            "                                                                 \n",
            " conv2d_185 (Conv2D)         (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " batch_normalization_210 (Ba  (None, 112, 112, 128)    512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_210 (Activation)  (None, 112, 112, 128)    0         \n",
            "                                                                 \n",
            " max_pooling2d_66 (MaxPoolin  (None, 56, 56, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_186 (Conv2D)         (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_211 (Ba  (None, 56, 56, 256)      1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_211 (Activation)  (None, 56, 56, 256)      0         \n",
            "                                                                 \n",
            " conv2d_187 (Conv2D)         (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_212 (Ba  (None, 56, 56, 256)      1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_212 (Activation)  (None, 56, 56, 256)      0         \n",
            "                                                                 \n",
            " conv2d_188 (Conv2D)         (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_213 (Ba  (None, 56, 56, 256)      1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_213 (Activation)  (None, 56, 56, 256)      0         \n",
            "                                                                 \n",
            " max_pooling2d_67 (MaxPoolin  (None, 28, 28, 256)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_189 (Conv2D)         (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " batch_normalization_214 (Ba  (None, 28, 28, 512)      2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_214 (Activation)  (None, 28, 28, 512)      0         \n",
            "                                                                 \n",
            " conv2d_190 (Conv2D)         (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " batch_normalization_215 (Ba  (None, 28, 28, 512)      2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_215 (Activation)  (None, 28, 28, 512)      0         \n",
            "                                                                 \n",
            " conv2d_191 (Conv2D)         (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " batch_normalization_216 (Ba  (None, 28, 28, 512)      2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_216 (Activation)  (None, 28, 28, 512)      0         \n",
            "                                                                 \n",
            " max_pooling2d_68 (MaxPoolin  (None, 14, 14, 512)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_192 (Conv2D)         (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " batch_normalization_217 (Ba  (None, 14, 14, 512)      2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_217 (Activation)  (None, 14, 14, 512)      0         \n",
            "                                                                 \n",
            " conv2d_193 (Conv2D)         (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " batch_normalization_218 (Ba  (None, 14, 14, 512)      2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_218 (Activation)  (None, 14, 14, 512)      0         \n",
            "                                                                 \n",
            " conv2d_194 (Conv2D)         (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " batch_normalization_219 (Ba  (None, 14, 14, 512)      2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_219 (Activation)  (None, 14, 14, 512)      0         \n",
            "                                                                 \n",
            " max_pooling2d_69 (MaxPoolin  (None, 7, 7, 512)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 4096)              102764544 \n",
            "                                                                 \n",
            " batch_normalization_220 (Ba  (None, 4096)             16384     \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_220 (Activation)  (None, 4096)             0         \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 4096)              16781312  \n",
            "                                                                 \n",
            " batch_normalization_221 (Ba  (None, 4096)             16384     \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_221 (Activation)  (None, 4096)             0         \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 138,407,208\n",
            "Trainable params: 138,382,376\n",
            "Non-trainable params: 24,832\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}