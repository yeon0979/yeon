{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNu4FKs79hxRS4g4+X2UY39"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "FCN: VGG16에서 FC layer에 해당하는 부분을 Conv layer로 만들어서 segmentation 성능 향상<br>\n",
        "1. Conv로 만들어진 feature맵에 FC를 적용하면 원본 이미지에서의 좌표정보가 사라져서 segmentation 성능이 떨어지는데 이를 보완하기 위해 FC layer를 Conv화 한 모델<br>\n",
        "2. FC layer를 없애고 Conv2DTranspose를 이용해 upsampling을 통한 decoding으로 segmentation 수행\n",
        "3. upsampling 후 1x1 Conv를 왜 하는지는 아직 이해 못함 이 부분 더 생각 해봐야됨"
      ],
      "metadata": {
        "id": "3CMP7f_RcBTP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "원본 논문\n",
        "- https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf"
      ],
      "metadata": {
        "id": "Iq568sbvb39v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VGG16"
      ],
      "metadata": {
        "id": "ZfpRbDTQet4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D, Dense, Dropout\n",
        "from keras.layers import BatchNormalization, Activation, Concatenate\n",
        "from keras.models import Model\n",
        "\n",
        "def VGG_Conv2D(z, n_convs=2, f=64, k=(3, 3), s=(1, 1), p=\"same\"):\n",
        "    \"\"\"\n",
        "    input\n",
        "        : input tensor of Convolution layer\n",
        "    n_convs\n",
        "        : Number of iterations of Conv-Pooling\n",
        "    f\n",
        "        : filter size of Conv\n",
        "    k\n",
        "        : kernel size of Conv\n",
        "    s\n",
        "        : stride size of Conv\n",
        "    p\n",
        "        : padding status of Conv\n",
        "    \"\"\"\n",
        "\n",
        "    for i in range(n_convs):\n",
        "        z = Conv2D(filters=f, kernel_size=k, strides=s, padding=p, use_bias=False)(z)\n",
        "        z = BatchNormalization()(z)\n",
        "        z = Activation(\"relu\")(z)\n",
        "    z = MaxPooling2D(pool_size=(2, 2), strides=2)(z)\n",
        "    return z\n",
        "\n",
        "input = Input([224, 224, 3], dtype=tf.float32)\n",
        "\n",
        "x = VGG_Conv2D(input, n_convs=2, f=64, k=(3, 3), s=(1, 1), p=\"same\")\n",
        "x = VGG_Conv2D(x, f=128)\n",
        "x = VGG_Conv2D(x, n_convs=3, f=256)\n",
        "x = VGG_Conv2D(x, n_convs=3, f=512)\n",
        "x = VGG_Conv2D(x, n_convs=3, f=512)\n",
        "\n",
        "x = Flatten()(x)\n",
        "# x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "x = Dense(4096, use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = Dense(4096, use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "output = Dense(1000, activation=\"softmax\")(x)\n",
        "\n",
        "model = Model(inputs=input, outputs=output)"
      ],
      "metadata": {
        "id": "KD75Lbs4e4VF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FCN"
      ],
      "metadata": {
        "id": "CP4ROmsMfJAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.layers.UpSampling2D(\n",
        "    size=(2, 2), data_format=None, interpolation='bilinear', **kwargs\n",
        ")"
      ],
      "metadata": {
        "id": "TL69xZwCiquw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = Input([224, 224, 3], dtype=tf.float32)\n",
        "\n",
        "x = VGG_Conv2D(input, n_convs=2, f=64, k=(3, 3), s=(1, 1), p=\"same\")\n",
        "x = VGG_Conv2D(x, f=128)\n",
        "x = VGG_Conv2D(x, n_convs=3, f=256)\n",
        "f3 = x # (28, 28, 256)\n",
        "x = VGG_Conv2D(x, n_convs=3, f=512)\n",
        "f4 = x # (14, 14, 512)\n",
        "x = VGG_Conv2D(x, n_convs=3, f=512)\n",
        "f5 = x # (7, 7, 512)"
      ],
      "metadata": {
        "id": "vAaZfoSYfOZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upsampling - Conv2DTranspose\n",
        "- https://velog.io/@hayaseleu/Transposed-Convolutional-Layer%EC%9D%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80"
      ],
      "metadata": {
        "id": "LnMi3kHUviDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use PASCAL VOC (including background)\n",
        "n_classes = 21"
      ],
      "metadata": {
        "id": "1xw00BiK_bLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### FCN-32"
      ],
      "metadata": {
        "id": "9QfsJA1p_shk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FCN-32 output\n",
        "# 32x Upsampling for 5th feature map and use predict result\n",
        "fcn32 = tf.keras.layers.Conv2DTranspose(n_classes, kernel_size=(32, 32), strides=(32, 32), use_bias=False)(f5)\n",
        "fcn32 = tf.keras.layers.Activation('softmax')(fcn32)\n",
        "\n",
        "print(fcn32.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v342gAY0_HvW",
        "outputId": "bd5571cf-47c4-4e99-800e-de29a46fc72d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 224, 224, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### FCN-16"
      ],
      "metadata": {
        "id": "a50qY0Pi_vu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4x Upsampling for 5th feature map\n",
        "x = tf.keras.layers.Conv2DTranspose(n_classes, kernel_size=(4, 4), strides=(2, 2), use_bias=False)(f5) # (16, 16, n)\n",
        "x = tf.keras.layers.Cropping2D(cropping=(1, 1))(x) # (14, 14, n)\n",
        "\n",
        "# 1x1 Conv for 4th feature map\n",
        "x2 = tf.keras.layers.Conv2D(n_classes, (1, 1), activation='relu', padding='same')(f4) # (14, 14, n)\n",
        "\n",
        "# concat result of upsampling and 1x1 Conv\n",
        "x = Concatenate()([x, x2]) # (14, 14, n)\n",
        "\n",
        "# 16x Upsampling for x and use predict result\n",
        "fcn16 = tf.keras.layers.Conv2DTranspose(n_classes, kernel_size=(16, 16), strides=(16, 16), use_bias=False)(x)\n",
        "fcn16 = tf.keras.layers.Activation('softmax')(fcn16)\n",
        "\n",
        "print(fcn16.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MgcIGCm_PSk",
        "outputId": "4bd19dc2-19a7-4229-e8cd-00cccbb741be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 224, 224, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### FCN-8"
      ],
      "metadata": {
        "id": "MDY8t2RS_yur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4x Upsampling for 5th feature map\n",
        "x = tf.keras.layers.Conv2DTranspose(n_classes, kernel_size=(4, 4), strides=(2, 2), use_bias=False)(f5) # (16, 16, n)\n",
        "x = tf.keras.layers.Cropping2D(cropping=(1, 1))(x) # (14, 14, n)\n",
        "\n",
        "# 1x1 Convolution for 4th feature map\n",
        "x2 = tf.keras.layers.Conv2D(n_classes, (1, 1), activation='relu', padding='same')(f4) # (14, 14, n)\n",
        "\n",
        "# concat result of upsampling and 1x1 Conv\n",
        "x = Concatenate()([x, x2]) # (14, 14, n)\n",
        "\n",
        "# 4x Upsampling for x\n",
        "x = tf.keras.layers.Conv2DTranspose(n_classes, kernel_size=(4, 4), strides=(2, 2), use_bias=False)(x) # (30, 30, n)\n",
        "x = tf.keras.layers.Cropping2D(cropping=(1, 1))(x) # (28, 28, n)\n",
        "\n",
        "# 1x1 Conn for 3rd feature map\n",
        "x2 = tf.keras.layers.Conv2D(n_classes, (1, 1), activation='relu', padding='same')(f3) # (28, 28, n)\n",
        "\n",
        "# concat result of upsampling and 1x1 Conv\n",
        "x = Concatenate()([x, x2]) # (28, 28, n)\n",
        "\n",
        "# 8x Upsampling for 5th feature map and use predict result\n",
        "x = tf.keras.layers.Conv2DTranspose(n_classes, kernel_size=(8, 8), strides=(8, 8), use_bias=False)(x) # (224, 224, n)\n",
        "fcn8 = tf.keras.layers.Activation('softmax')(x)\n",
        "\n",
        "print(fcn8.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulJ5fMjBuU0J",
        "outputId": "9c751208-f895-41cc-e626-841e7354dd23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 224, 224, 21)\n"
          ]
        }
      ]
    }
  ]
}